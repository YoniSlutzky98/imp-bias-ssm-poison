{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d56d4eab-fad5-4a10-8bd1-91776b41e022",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef4758-0b30-4da7-b03e-0814fcc32f6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7c159-a637-4726-b88f-e77b92864c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2a60e-3807-4080-a4ed-07c82267bf3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Generic Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27686e-0644-4adc-aecc-b7f7dbd3b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_reals_with_sum_of_squares(P, n, seed):\n",
    "    '''\n",
    "    Generates random samples with a square sum of P.\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    x = np.random.normal(0, 1, n)\n",
    "    S = np.sum(x**2)\n",
    "    scale_factor = np.sqrt(P / S)\n",
    "    y = x * scale_factor\n",
    "    return y\n",
    "\n",
    "def impulse(A, B, C, length):\n",
    "    '''\n",
    "    Computes the entry in index length of the impulse response induced by the SSM parameterized by (A, B, C).\n",
    "    '''\n",
    "    A = np.diag(A)\n",
    "    return C @ np.linalg.matrix_power(A, length - 1) @ B\n",
    "\n",
    "def compute_grad(A, length, x_long, x_short, B, C, Astar, Bstar, Cstar):\n",
    "    '''\n",
    "    Manually computes the gradient of the objective. \n",
    "    '''\n",
    "    diag_long = np.zeros((A.shape[0]))\n",
    "    res = impulse(A, B, C, length) - impulse(Astar, Bstar, Cstar, length)\n",
    "    for k in range(len(x_long)):\n",
    "        diag_long += (np.diag(C.T @ B.T) * res * (x_long[k] ** 2)).flatten()\n",
    "    \n",
    "    diag_short = np.zeros((A.shape[0]))\n",
    "    res = impulse(A, B, C, 2) - impulse(Astar, Bstar, Cstar, 2)\n",
    "    for k in range(len(x_short)):\n",
    "        diag_short += (np.diag(C.T @ B.T) * res * (x_short[k] ** 2)).flatten()\n",
    "    \n",
    "    return - 2 / (len(x_long) + len(x_short)) * ((length - 1) * (A ** (length - 2)) * diag_long + diag_short)\n",
    "\n",
    "def model(A, timestamps, length, x_long, x_short, B, C, Astar, Bstar, Cstar):\n",
    "    '''\n",
    "    The function used as input to odeint. \n",
    "    Intakes the model's parameter matrix A and the required timestamps.\n",
    "    Returns the gradient of the objective at A. \n",
    "    '''\n",
    "    da = compute_grad(A, length, x_long, x_short, B, C, Astar, Bstar, Cstar)\n",
    "    return da\n",
    "\n",
    "def compute_logs(timestamps, A, length, x_long, x_short, B, C, Astar, Bstar, Cstar, ext_start, ext_end):\n",
    "    '''\n",
    "    Logging function. \n",
    "    Intakes the timestamps and the approximated A values.\n",
    "    Returns the train losses and extrapolation losses for the given timestamps. \n",
    "    '''\n",
    "    train_losses = np.zeros(timestamps.shape[0])\n",
    "    ext_losses = np.zeros(timestamps.shape[0])\n",
    "\n",
    "    ell_infty = 0\n",
    "    for j in range(ext_start, ext_end + 1):\n",
    "        ell_infty = max(ell_infty, impulse(Astar, Bstar, Cstar, j))\n",
    "    \n",
    "    for t in range(timestamps.shape[0]):\n",
    "        res = impulse(A[t, :], B, C, length) - impulse(Astar, Bstar, Cstar, length)\n",
    "        for k in range(len(x_long)):\n",
    "            train_losses[t] += (res * x_long[k]) ** 2\n",
    "        res = impulse(A[t, :], B, C, 2) - impulse(Astar, Bstar, Cstar, 2)\n",
    "        for k in range(len(x_short)):\n",
    "            train_losses[t] += (res * x_short[k]) ** 2\n",
    "        train_losses[t] /= (len(x_long) + len(x_short))\n",
    "        \n",
    "        for j in range(ext_start, ext_end + 1):\n",
    "            res = impulse(A[t, :], B, C, j) - impulse(Astar, Bstar, Cstar, j)\n",
    "            ext_losses[t] = max(ext_losses[t], np.abs(res))\n",
    "        ext_losses[t] /= ell_infty\n",
    "        \n",
    "    return train_losses, ext_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d6ab3-46f8-45a4-9479-b5d4cbfc6728",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd83520-40f0-44fc-b51f-97458e239c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(seed, hidden_dim, sd_A, length, x_long, x_short, B, C, Astar, Bstar, Cstar, stop, step, ext_start, \n",
    "             ext_end, diff):\n",
    "    '''\n",
    "    Simulates the optimization of A via gradient flow on the objective.\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    A0 = np.flip(np.sort(sd_A * np.random.rand(hidden_dim)))\n",
    "    A0[1] = A0[0] - diff\n",
    "    train_losses, ext_losses = [], []\n",
    "    timestamps = np.linspace(0, stop, step)\n",
    "    A = odeint(model, A0, timestamps, args=(length, x_long, x_short, B, C, Astar, Bstar, Cstar))\n",
    "    train_losses, ext_losses = compute_logs(timestamps, A, length, x_long, x_short, B, C, Astar, Bstar, Cstar, ext_start, ext_end)\n",
    "    return (train_losses[-1], ext_losses[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62668d8f-3d07-4005-8d10-5ebf6c418287",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Length = 7, teacher state dim = 2, student state dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d3b9b3-4879-4380-bac1-c14d5df79971",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec99cb4-3735-45c1-a95c-45bd95e76745",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [242+i for i in [0, 2, 4, 5]]\n",
    "teacher_hidden_dim = 2\n",
    "student_hidden_dim = 10\n",
    "length = 7\n",
    "ext_start = 1\n",
    "ext_end = 20\n",
    "Bstar = np.zeros((teacher_hidden_dim, 1))\n",
    "Cstar = np.ones((1, teacher_hidden_dim))\n",
    "Astar = np.zeros((teacher_hidden_dim))\n",
    "Astar[0] = 1\n",
    "Bstar[0, 0] = 1\n",
    "Bstar[1, 0] = np.sqrt(student_hidden_dim - 1)\n",
    "Cstar = Bstar.T\n",
    "B = np.ones((student_hidden_dim, 1))\n",
    "C = B.T\n",
    "sd_A = 0.001\n",
    "diff = 0.05 / np.exp(5 * np.log10(1 / sd_A))\n",
    "P = 10\n",
    "n_long = 5\n",
    "n_short = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4e22d-9a8a-4e08-94bc-a6f43c5905a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training only using baseline sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a329b8-a6ef-4241-bfe5-435984333a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = 100000000000\n",
    "step = 1000\n",
    "avg_train_loss = 0\n",
    "avg_ext_loss = 0\n",
    "for seed in seeds:\n",
    "    x_long = sample_reals_with_sum_of_squares(P, n_long, seed)\n",
    "    x_short = []\n",
    "    train_loss, ext_loss = simulate(seed, student_hidden_dim, sd_A, length, x_long, x_short, B, C, Astar, Bstar, \n",
    "                                    Cstar, stop, step, ext_start, ext_end, diff)\n",
    "    avg_train_loss += train_loss\n",
    "    avg_ext_loss += ext_loss\n",
    "    print('--------------------------------')\n",
    "    print(f'Results for seed={seed}:')\n",
    "    print(f'Train loss: {train_loss}')\n",
    "    print(f'Extrapolation loss: {ext_loss}')\n",
    "avg_train_loss /= len(seeds)\n",
    "avg_ext_loss /= len(seeds)\n",
    "print('--------------------------------')\n",
    "print('Overall results:')\n",
    "print(f'Mean train loss: {avg_train_loss}')\n",
    "print(f'Mean extrapolation loss: {avg_ext_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab809c-9cbf-4dbd-a13f-5dbc0618e5a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training using baseline and special sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f23c3-6426-4e3d-a9fd-e1134a490b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = 10000\n",
    "step = 1000\n",
    "avg_train_loss = 0\n",
    "avg_ext_loss = 0\n",
    "for seed in seeds:\n",
    "    x_long = sample_reals_with_sum_of_squares(P, n_long, seed)\n",
    "    x_short = sample_reals_with_sum_of_squares(P, n_short, seed+12)\n",
    "    train_loss, ext_loss = simulate(seed, student_hidden_dim, sd_A, length, x_long, x_short, B, C, Astar, Bstar, \n",
    "                                    Cstar, stop, step, ext_start, ext_end, diff)\n",
    "    avg_train_loss += train_loss\n",
    "    avg_ext_loss += ext_loss\n",
    "    print('--------------------------------')\n",
    "    print(f'Results for seed={seed}:')\n",
    "    print(f'Train loss: {train_loss}')\n",
    "    print(f'Extrapolation loss: {ext_loss}')\n",
    "avg_train_loss /= len(seeds)\n",
    "avg_ext_loss /= len(seeds)\n",
    "print('--------------------------------')\n",
    "print('Overall results:')\n",
    "print(f'Mean train loss: {avg_train_loss}')\n",
    "print(f'Mean extrapolation loss: {avg_ext_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c04541-4f7c-4445-8d1f-aa68a45ab221",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Length = 10, teacher state dim = 2, student state dim = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83029789-6083-4bba-a708-54f2fde9188f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63067dd-8736-4193-acf1-f8b3e659688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [342+i for i in [0, 2, 3, 4]]\n",
    "teacher_hidden_dim = 2\n",
    "student_hidden_dim = 20\n",
    "length = 9\n",
    "ext_start = 1\n",
    "ext_end = 20\n",
    "Bstar = np.zeros((teacher_hidden_dim, 1))\n",
    "Cstar = np.ones((1, teacher_hidden_dim))\n",
    "Astar = np.zeros((teacher_hidden_dim))\n",
    "Astar[0] = 1\n",
    "Bstar[0, 0] = 1\n",
    "Bstar[1, 0] = np.sqrt(student_hidden_dim - 1)\n",
    "Cstar = Bstar.T\n",
    "B = np.ones((student_hidden_dim, 1))\n",
    "C = B.T\n",
    "sd_A = 0.005\n",
    "diff = 0.05 / np.exp(10 * np.log10(1 / sd_A))\n",
    "P = 10\n",
    "n_long = 5\n",
    "n_short = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865b214-2642-4dfc-9a07-61cece65d2ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training only using baseline sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf8014-f1b6-433e-9c32-2001043b852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = 1000000000000\n",
    "step = 10000\n",
    "avg_train_loss = 0\n",
    "avg_ext_loss = 0\n",
    "for seed in seeds:\n",
    "    x_long = sample_reals_with_sum_of_squares(P, n_long, seed)\n",
    "    x_short = []\n",
    "    train_loss, ext_loss = simulate(seed, student_hidden_dim, sd_A, length, x_long, x_short, B, C, Astar, Bstar, \n",
    "                                    Cstar, stop, step, ext_start, ext_end, diff)\n",
    "    avg_train_loss += train_loss\n",
    "    avg_ext_loss += ext_loss\n",
    "    print('--------------------------------')\n",
    "    print(f'Results for seed={seed}:')\n",
    "    print(f'Train loss: {train_loss}')\n",
    "    print(f'Extrapolation loss: {ext_loss}')\n",
    "avg_train_loss /= len(seeds)\n",
    "avg_ext_loss /= len(seeds)\n",
    "print('--------------------------------')\n",
    "print('Overall results:')\n",
    "print(f'Mean train loss: {avg_train_loss}')\n",
    "print(f'Mean extrapolation loss: {avg_ext_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ebfbb-d45c-473e-bf4c-1b5bd16d8cf8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training using baseline and special sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24797508-02eb-402f-b56e-bb46e51febb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = 1000000\n",
    "step = 1000\n",
    "avg_train_loss = 0\n",
    "avg_ext_loss = 0\n",
    "for seed in seeds:\n",
    "    x_long = sample_reals_with_sum_of_squares(P, n_long, seed)\n",
    "    x_short = sample_reals_with_sum_of_squares(P, n_short, seed+12)\n",
    "    train_loss, ext_loss = simulate(seed, student_hidden_dim, sd_A, length, x_long, x_short, B, C, Astar, Bstar, \n",
    "                                    Cstar, stop, step, ext_start, ext_end, diff)\n",
    "    avg_train_loss += train_loss\n",
    "    avg_ext_loss += ext_loss\n",
    "    print('--------------------------------')\n",
    "    print(f'Results for seed={seed}:')\n",
    "    print(f'Train loss: {train_loss}')\n",
    "    print(f'Extrapolation loss: {ext_loss}')\n",
    "avg_train_loss /= len(seeds)\n",
    "avg_ext_loss /= len(seeds)\n",
    "print('--------------------------------')\n",
    "print('Overall results:')\n",
    "print(f'Mean train loss: {avg_train_loss}')\n",
    "print(f'Mean extrapolation loss: {avg_ext_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
